{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"guardian_archive.csv -- Файл с собранными новостями с 01.01.2017 по 01.11.2023.\"\"\"\n",
    "df = pd.read_csv('guardian_archive.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ВНИМАНИЕ! Это вспомогательные функции, которые может быть понадобятся потом.\n",
    "Используем их для того, если вдруг нужно будет из csv файла создать таблицу и положить в бд.\n",
    "1. Настраивает соединение с бд.\n",
    "2. Создает таблицу в базе данных.\n",
    "Таким образом, можно будет использовать в других шагах проекта\"\"\"\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "def create_connection_to_db(path):#1\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = psycopg2.connect(dbname=path, user='user', \n",
    "                        password='password', host='localhost')\n",
    "        print(\"Connection to PostgreSQL DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "def create_table_and_insert_data_from_csv(connection, csv_file_path, table_name):#2\n",
    "\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df = df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)#использовать, если есть ненужные столбцы \n",
    "    \n",
    "    # Устанавливаем соединение с базой данных\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    #Создаем запрос на создание таблицы с первичным ключом news_id и колонками из датафрейма с типом данных TEXT(по необходимости)\n",
    "    create_table_query = f'CREATE TABLE IF NOT EXISTS {table_name} (news_id SERIAL PRIMARY KEY, {\" ,\".join([f\"{column} TEXT\" for column in df.columns])})'\n",
    "    \n",
    "    # Создаем запрос для внесения данных в таблицу\n",
    "    insert_query = f'INSERT INTO {table_name} ({\", \".join(df.columns)}) VALUES ({\", \".join([\"%s\"] * len(df.columns))})'\n",
    "    \n",
    "    # Выполняем SQL-запрос для создания таблицы\n",
    "    cursor.execute(create_table_query)\n",
    "    \n",
    "    # Вставляем данные\n",
    "    for _, row in df.iterrows():\n",
    "        cursor.execute(insert_query, row)\n",
    "    \n",
    "    # комитимся\n",
    "    connection.commit()\n",
    "    \n",
    "    # Закрываем курсор\n",
    "    cursor.close()\n",
    "\n",
    "# Создаем подключение к PostgreSQL\n",
    "connection = create_connection_to_db('postgres')#dbname=path\n",
    "\n",
    "# Создаем таблицу и вставляем данные из CSV-файла\n",
    "create_table_and_insert_data_from_csv(connection, 'guardian_archive.csv', 'news_guardian')\n",
    "\n",
    "# Закрываем соединение с базой данных\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обновление таблицы новостей и записи в логи(пока только текстовый файл)\n",
    "import requests\n",
    "from datetime import datetime, timedelta, date\n",
    "import logging\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(filename='update_database.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - update_database - %(message)s')\n",
    "\n",
    "\n",
    "# Функция для создания соединения с базой данных PostgreSQL. Создал отдельно еще одну для удобства\n",
    "def create_connection(database_name, user, password, host, port):\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            database=database_name,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            port=port\n",
    "        )\n",
    "        connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        return connection\n",
    "    except Error as e:\n",
    "        raise Exception(f\"Ошибка при подключении к базе данных: {str(e)}\")\n",
    "\n",
    "def update_database(start_date, end_date):\n",
    "    success = False  # Флаг успешного обновления. Изначально считаем, что обновление неуспешно\n",
    "    try:\n",
    "        # Чтение API-ключа из файла\n",
    "        with open('api_key.txt', 'r') as api_key_file:\n",
    "            api_key = api_key_file.read().strip()\n",
    "\n",
    "        # Чтение ключевых слов из файла\n",
    "        with open('tags.txt', 'r') as file:\n",
    "            tags = [line.strip() for line in file]\n",
    "\n",
    "        result_data = []\n",
    "\n",
    "        while start_date <= end_date:\n",
    "            # Объединяем теги в одну строку через '|'. В документации означет OR\n",
    "            tags_query = '|'.join(tags)\n",
    "\n",
    "            params = {\n",
    "                'api-key': api_key,\n",
    "                'q': tags_query,\n",
    "                'from-date': start_date,\n",
    "                'to-date': end_date,\n",
    "                'page-size': 100,\n",
    "                'show-fields': ['body', 'bodyText']\n",
    "            }\n",
    "\n",
    "            url = 'https://content.guardianapis.com/search'\n",
    "\n",
    "            response = requests.get(url, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for article in data['response']['results']:\n",
    "                    # Определяем список тегов, которые были найдены в тексте статьи или в заголовке\n",
    "                    found_tags = [tag for tag in tags if (tag.lower() in article['webTitle'].lower()) or (tag.lower() in article['fields']['bodyText'].lower())]\n",
    "                    if found_tags:\n",
    "                        result_data.append({\n",
    "                            'type': article['type'],\n",
    "                            'sectionId': article['sectionId'],\n",
    "                            'sectionName': article['sectionName'],\n",
    "                            'webPublicationDate': article['webPublicationDate'],\n",
    "                            'webTitle': article['webTitle'],\n",
    "                            'text': article['fields']['bodyText'],\n",
    "                            'webUrl': article['webUrl'],\n",
    "                            'apiUrl': article['apiUrl'],\n",
    "                            'searchedTags': '/'.join(found_tags)  # Используем только найденные теги\n",
    "                        })\n",
    "\n",
    "                #Соединяем теги через '/' и переводим теги слитно в вид CamelCase\n",
    "                df = pd.DataFrame(result_data)\n",
    "                df['searchedTags'] = df['searchedTags'].apply(lambda tags: '/'.\n",
    "                                                              join([''.join(word.title() for word in tag.split())\n",
    "                                                                    if ' ' in tag else tag for tag in tags.split('/')]))\n",
    "                tags = df['searchedTags'].str.split('/').sum()\n",
    "                unique_tags = list(set(tags))\n",
    "\n",
    "                #Создаем колонки для тегов. Пока ставим признак, что тег отсутствует\n",
    "                for tag in unique_tags:\n",
    "                    df[tag] = 0\n",
    "\n",
    "                # Ставим 1 к колонке с признаком, если он есть в searchedTags\n",
    "                for index, row in df.iterrows():\n",
    "                    for tag in row['searchedTags'].split('/'):\n",
    "                        if tag in unique_tags:\n",
    "                            df.at[index, tag] = 1\n",
    "\n",
    "                # Преобразование даты \n",
    "                df['webPublicationDate'] = pd.to_datetime(df['webPublicationDate']).dt.strftime('%Y-%m-%d')\n",
    "                # Подключаемся к базе данных PostgreSQL\n",
    "                connection = create_connection('db_name', 'user', 'password', 'localhost', '5432')\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Вставляем данные в таблицу. По итогу найденные новости и созданные признаки тегов отправляются в БД\n",
    "                # На ошибку при вставке не нарываемся, так как признакам поставлен параметр DEFAULT 0\n",
    "                for _, row in df.iterrows():\n",
    "                    placeholders = ', '.join(['%s'] * len(unique_tags))\n",
    "                    columns = ', '.join(unique_tags)\n",
    "                    query = f\"INSERT INTO news_guardian (type, sectionId, sectionName, webPublicationDate, webTitle, text, webUrl, apiUrl, searchedTags, {columns}) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, {placeholders})\"\n",
    "    \n",
    "                    cursor.execute(query, (row['type'], row['sectionId'], row['sectionName'], row['webPublicationDate'], row['webTitle'],\n",
    "                            row['text'], row['webUrl'], row['apiUrl'], row['searchedTags'], *[row[tag] for tag in unique_tags]))\n",
    "\n",
    "                connection.commit()\n",
    "                cursor.close()\n",
    "\n",
    "                start_date = (date.fromisoformat(start_date) + timedelta(days=1)).isoformat()\n",
    "            else:\n",
    "                error_message = f\"Ошибка при запросе к API: {response.status_code}\"\n",
    "                logging.error(error_message)\n",
    "                print(error_message)\n",
    "                raise Exception(error_message)# Эти ошибки возникают при сбое в работе с API\n",
    "\n",
    "        success = True  # Обновление успешно завершено. В консоль успех не выводим\n",
    "        logging.info(\"Обновление базы данных завершено успешно!\")\n",
    "\n",
    "    except Exception as e: #Остальные ошибки\n",
    "        error_message = f\"Произошла ошибка: {str(e)}\"\n",
    "        logging.error(error_message)\n",
    "        print(error_message)\n",
    "\n",
    "    if not success:\n",
    "        logging.warning(\"Обновление базы данных завершилось с ошибкой!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    end_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "    update_database(start_date, end_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
